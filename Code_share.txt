# Load necessary libraries
if (!requireNamespace("aws.s3", quietly = TRUE)) install.packages("aws.s3")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("readr", quietly = TRUE)) install.packages("readr")

library(aws.s3)
library(dplyr)
library(readr)

# Function to parse S3 path
parse_s3_path <- function(s3_path) {
  print(paste("Parsing S3 path:", s3_path))
  if (grepl("^s3://", s3_path)) {
    s3_path <- gsub("s3://", "", s3_path)
    parts <- strsplit(s3_path, "/", fixed = TRUE)[[1]]
    bucket_name <- parts[1]
    object_key <- paste(parts[-1], collapse = "/")
    list(bucket_name = bucket_name, object_key = object_key)
  } else {
    stop("Invalid S3 path format. Path should start with 's3://'.")
  }
}

# Read command line arguments
args <- commandArgs(trailingOnly = TRUE)
print("Command line arguments received:")
print(args)

if (length(args) < 2) {
  stop("Please provide input and output S3 paths as command line arguments.")
}
input_path <- args[1]
output_path <- args[2]

# Log the provided arguments
print(paste("Input Path Argument:", input_path))
print(paste("Output Path Argument:", output_path))

# Parse S3 paths
input_s3 <- parse_s3_path(input_path)
output_s3 <- parse_s3_path(output_path)

# Log the parsed paths
print(paste("Parsed Input S3 Path - Bucket:", input_s3$bucket_name, "Key:", input_s3$object_key))
print(paste("Parsed Output S3 Path - Bucket:", output_s3$bucket_name, "Key:", output_s3$object_key))

# List objects in the input S3 path
print("Listing objects in the input S3 path...")
objects <- get_bucket(input_s3$bucket_name, prefix = input_s3$object_key)

# Filter for CSV files and select the first one
csv_files <- objects[grepl("\\.csv$", sapply(objects, function(x) x$Key))]
if (length(csv_files) == 0) {
  stop("No CSV files found in the input path.")
}
input_csv_key <- csv_files[[1]]$Key
print(paste("Selected CSV file:", input_csv_key))

# Download the selected CSV file from S3
print("Downloading CSV file from S3...")
input_file <- s3read_using(FUN = read_csv, object = input_csv_key, bucket = input_s3$bucket_name)

# Data cleaning (example: removing rows with NA values)
print("Cleaning data...")
cleaned_data <- input_file %>%
  drop_na()

# Save cleaned data to a temporary file
temp_file <- tempfile(fileext = ".csv")
print(paste("Saving cleaned data to temporary file:", temp_file))
write_csv(cleaned_data, temp_file)

# Upload cleaned CSV file to S3
print("Uploading cleaned data to S3...")
put_object(file = temp_file, object = output_s3$object_key, bucket = output_s3$bucket_name)

# Clean up temporary file
file.remove(temp_file)

# Print success message
print("Data cleaned and uploaded to S3 successfully.")
